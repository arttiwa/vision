{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc805a3-5c94-4dbd-8178-d6034a140255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening image!\n",
      "Usage: hough_circle.py [image_name -- default C:\\Users\\thiwa\\vision\\IMG\\1.jpg] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def main(argv):\n",
    "    default_file = r'C:\\Users\\thiwa\\vision\\IMG\\1.jpg'\n",
    "    filename = argv[0] if len(argv) > 0 else default_file\n",
    "\n",
    "    # Loads an image\n",
    "    src = cv.imread(filename, cv.IMREAD_COLOR)\n",
    "\n",
    "    # Check if image is loaded fine\n",
    "    if src is None:\n",
    "        print('Error opening image!')\n",
    "        print('Usage: hough_circle.py [image_name -- default ' + default_file + '] \\n')\n",
    "        return -1\n",
    "\n",
    "    gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "    gray = cv.medianBlur(gray, 5)\n",
    "\n",
    "    rows = gray.shape[0]\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, rows / 8,\n",
    "                              param1=100, param2=30, minRadius=1, maxRadius=30)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for i in circles[0, :]:\n",
    "            center = (i[0], i[1])\n",
    "            # circle center\n",
    "            cv.circle(src, center, 1, (0, 100, 100), 3)\n",
    "            # circle outline\n",
    "            radius = i[2]\n",
    "            cv.circle(src, center, radius, (255, 0, 255), 3)\n",
    "\n",
    "    cv.imshow(\"detected circles\", src)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97761851-e4a6-490e-890a-802ba68bd034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b04560-754c-441f-98de-3f92bd7f2ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195ae4e-39bc-44ad-996a-aac1910a80e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc22a3-5f0a-4f21-af65-21b42393ce98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd487e-1f26-4c16-9415-b49334bec0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b79b9-b0fb-466a-b35a-723c029150ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d0a314-5fdc-47c9-ae09-85b025c012b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "frame = cv2.imread(r'C:\\Users\\thiwa\\vision\\IMG\\1.jpg') # Test Coin Picture-1\n",
    "\n",
    "result = frame.copy()\n",
    "gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray,(15,15),0)\n",
    "\n",
    "cv2.imshow(\"gray_blur\",gray_blur)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(gray_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,1)\n",
    "cv2.imshow(\"thresh\",thresh)\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "closing = cv2.morphologyEx(thresh,cv2.MORPH_CLOSE,kernel,iterations=4)\n",
    "result_img = closing.copy()\n",
    "cv2.imshow(\"closing\",result_img)\n",
    "contours,hierachy = cv2.findContours(result_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "counter = 0\n",
    "imgIn = frame.copy()\n",
    "\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    imgIn = cv2.drawContours(imgIn, cnt, -1, (255,0,0), 4)\n",
    "    if area<5000 or area > 35000:\n",
    "        continue\n",
    "    ellipse = cv2.fitEllipse(cnt)\n",
    "    cv2.ellipse(result,ellipse,(0,255,0),2)\n",
    "    counter += 1\n",
    "    \n",
    "cv2.imshow(\"Contours\",imgIn)\n",
    "cv2.putText(result,str(counter),(10,100),cv2.FONT_HERSHEY_SIMPLEX,4,(255,0,0),2,cv2.LINE_AA)\n",
    "cv2.imshow(\"Show\",result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6d88ee-1887-4c32-b3e1-b205e08b9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image using cv2.imread instead of VideoCapture\n",
    "frame = cv2.imread(r'C:\\Users\\thiwa\\vision\\IMG\\4.jpg')\n",
    "\n",
    "if frame is None:\n",
    "    print(\"Error: Image not loaded.\")\n",
    "    exit()\n",
    "\n",
    "# Define the region of interest (ROI)\n",
    "roi = frame[:1080, 0:1920]\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian Blur to the grayscale image\n",
    "gray_blur = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "\n",
    "# Apply adaptive thresholding\n",
    "thresh = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 1)\n",
    "\n",
    "# Perform morphological closing to close small holes\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=4)\n",
    "\n",
    "\n",
    "\n",
    "# Invert the colors of the closing result\n",
    "closing_inverted = cv2.bitwise_not(closing)\n",
    "\n",
    "# Display the closing result\n",
    "cv2.imshow(\"Closing Inverted\", closing_inverted)\n",
    "# Copy the closing result for contour detection\n",
    "result_img = closing_inverted.copy()\n",
    "\n",
    "\n",
    "# cv2.imshow(\"Closing\", closing)\n",
    "# result_img = closing.copy()\n",
    "\n",
    "\n",
    "contours, hierarchy = cv2.findContours(result_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "counter = 0\n",
    "imgIn = frame.copy()\n",
    "\n",
    "# Loop over the contours\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    # Draw the contour on the image\n",
    "    cv2.drawContours(imgIn, [cnt], -1, (255, 0, 0), 2)\n",
    "    # if area < 800  and area > 500: //\n",
    "    if area < 9990  and area > 10:\n",
    "        if len(cnt) >= 5:  # Ensure there are at least 5 points\n",
    "            ellipse = cv2.fitEllipse(cnt)\n",
    "            cv2.ellipse(roi, ellipse, (0, 255, 0), 2)\n",
    "            counter += 1\n",
    "\n",
    "# Put the counter text on the ROI\n",
    "cv2.putText(roi, str(counter), (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# Display the final image with contours and counter\n",
    "cv2.imshow(\"Contours\", imgIn)\n",
    "\n",
    "# Resize the \"Show\" window to 1500 pixels width and maintain the aspect ratio for height\n",
    "window_name = \"Show\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "height, width = roi.shape[:2]\n",
    "new_width = 1000\n",
    "new_height = int(height * (new_width / width))\n",
    "cv2.resizeWindow(window_name, new_width, new_height)\n",
    "\n",
    "cv2.imshow(window_name, roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b0987-1bbc-40f9-98c1-bac0bc921bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0fe75-2287-473a-9a79-9b2dd8825a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8935c-f615-4cb4-ab9b-c38b0e817c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7e701-4f33-4103-8597-665fbf5c618f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5baa54-4f28-481b-add4-175ea230a42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f270fa60-8fee-4f29-b8b5-6db0c0f4107b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(capture\u001b[38;5;241m.\u001b[39mread()) :\n\u001b[0;32m      9\u001b[0m     ref,frame \u001b[38;5;241m=\u001b[39m capture\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 10\u001b[0m     roi\u001b[38;5;241m=\u001b[39m\u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1080\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1920\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m     gray\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtColor(frame,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     13\u001b[0m     gray_blur\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray,(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m15\u001b[39m),\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image using cv2.imread instead of VideoCapture\n",
    "capture = cv2.VideoCapture(r'C:\\Users\\thiwa\\vision\\IMG\\5.jpg')\n",
    "\n",
    "\n",
    "while(capture.read()) :\n",
    "    ref,frame = capture.read()\n",
    "    roi=frame[:1080,0:1920]\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur=cv2.GaussianBlur(gray,(15,15),0)\n",
    "\n",
    "    thresh=cv2.adaptiveThreshold(gray_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,1)\n",
    "    kernel=np.ones((3,3),np.uint8)\n",
    "    closing=cv2.morphologyEx(thresh,cv2.MORPH_CLOSE,kernel,iterations=4)\n",
    "    result_img=closing.copy()\n",
    "\n",
    "    contours,hierachy=cv2.findContours(result_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    counter = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area<5000 or area > 35000:\n",
    "            continue\n",
    "        ellipse = cv2.fitEllipse(cnt)\n",
    "        cv2.ellipse(roi,ellipse,(0,0,255),5)\n",
    "        counter+=1\n",
    "    cv2.putText(roi,str(counter),(10,100),cv2.FONT_HERSHEY_SIMPLEX,4,(255,0,0),5,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Show\",roi)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f426ce7-be0b-407e-8d34-e78e6864bc81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
