{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_high_intensity_areas(image, threshold=20):\n",
    "    # Create a mask with the same dimensions as the image\n",
    "    mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "    \n",
    "    # Calculate the mean intensity of the image\n",
    "    mean_intensity = np.mean(image)\n",
    "    \n",
    "    # Thresholding to detect high intensity areas\n",
    "    _, mask = cv2.threshold(image, mean_intensity + threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours\n",
    "\n",
    "def draw_contours(image, contours):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "# Load images in grayscale\n",
    "img1 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t5.jpg\", 0)\n",
    "img2 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t7.jpg\", 0)\n",
    "\n",
    "# Detect high intensity areas\n",
    "contours1 = detect_high_intensity_areas(img1)\n",
    "display_contours1 = cv2.resize(contours1, (1000, 1000))\n",
    "contours2 = detect_high_intensity_areas(img2)\n",
    "display_contours2 = cv2.resize(contours2, (1000, 1000))\n",
    "\n",
    "# Draw contours on the images\n",
    "img1_with_contours = draw_contours(cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR), contours1)\n",
    "img2_with_contours = draw_contours(cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR), contours2)\n",
    "\n",
    "# Resize images for display\n",
    "display_img1 = cv2.resize(img1_with_contours, (1000, 1000))\n",
    "display_img2 = cv2.resize(img2_with_contours, (1000, 1000))\n",
    "\n",
    "# Show images\n",
    "cv2.imshow('Image 1 - High Intensity Areas', display_img1)\n",
    "cv2.imshow('contours1', display_contours1)\n",
    "cv2.imshow('Image 2 - High Intensity Areas', display_img2)\n",
    "cv2.imshow('contours2', display_contours2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_high_intensity_areas(image, threshold=20):\n",
    "    # Calculate the mean intensity of the image\n",
    "    mean_intensity = np.mean(image)\n",
    "    \n",
    "    # Thresholding to detect high intensity areas\n",
    "    _, mask = cv2.threshold(image, mean_intensity + threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours, mask\n",
    "\n",
    "def detect_high_intensity_areas2(image, threshold=20):\n",
    "    # Calculate the mean intensity of the image\n",
    "    mean_intensity = np.mean(image)\n",
    "    \n",
    "    # Thresholding to detect high intensity areas\n",
    "    _, mask = cv2.threshold(image, mean_intensity + threshold, 150, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours, mask\n",
    "\n",
    "def draw_contours(image, contours):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "def draw_contours2(image, contours):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def mask_detected_areas(image, mask):\n",
    "    # Apply the mask to the image to ignore detected areas\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
    "    return masked_image\n",
    "\n",
    "# Load images in grayscale\n",
    "img1 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t1.jpg\", 0)\n",
    "img2 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t2.jpg\", 0)\n",
    "\n",
    "# Detect high intensity areas and mask them\n",
    "contours1, mask1 = detect_high_intensity_areas(img1)\n",
    "img1_masked = mask_detected_areas(img1, mask1)\n",
    "\n",
    "contours2, mask2 = detect_high_intensity_areas(img2)\n",
    "img2_masked = mask_detected_areas(img2, mask2)\n",
    "\n",
    "# Detect new high intensity areas in the masked images\n",
    "new_contours1, _ = detect_high_intensity_areas2(img1_masked)\n",
    "new_contours2, _ = detect_high_intensity_areas2(img2_masked)\n",
    "\n",
    "# Draw contours on the original images\n",
    "img1_with_contours = draw_contours(cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR), contours1)\n",
    "img1_with_new_contours = draw_contours2(img1_with_contours, new_contours1)\n",
    "\n",
    "img2_with_contours = draw_contours(cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR), contours2)\n",
    "img2_with_new_contours = draw_contours2(img2_with_contours, new_contours2)\n",
    "\n",
    "# Resize images for display\n",
    "display_img1 = cv2.resize(img1_with_new_contours, (1000, 1000))\n",
    "display_img2 = cv2.resize(img2_with_new_contours, (1000, 1000))\n",
    "\n",
    "# Show images\n",
    "cv2.imshow('Image 1 - High Intensity Areas', display_img1)\n",
    "cv2.imshow('Image 2 - High Intensity Areas', display_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_low_intensity_areas(image, threshold=22.5):\n",
    "    # Calculate the mean intensity of the image\n",
    "    mean_intensity = np.mean(image)\n",
    "    \n",
    "    # Thresholding to detect low intensity areas\n",
    "    _, mask = cv2.threshold(image, mean_intensity - threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours, mask\n",
    "\n",
    "def draw_contours(image, contours):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def mask_detected_areas(image, mask):\n",
    "    # Apply the mask to the image to ignore detected areas\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
    "    return masked_image\n",
    "\n",
    "# Load images in grayscale\n",
    "img1 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t5.jpg\", 0)\n",
    "img2 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t7.jpg\", 0)\n",
    "\n",
    "# Detect low intensity areas and mask them\n",
    "contours1, mask1 = detect_low_intensity_areas(img1)\n",
    "img1_masked = mask_detected_areas(img1, mask1)\n",
    "\n",
    "contours2, mask2 = detect_low_intensity_areas(img2)\n",
    "img2_masked = mask_detected_areas(img2, mask2)\n",
    "\n",
    "# Detect new low intensity areas in the masked images\n",
    "new_contours1, _ = detect_low_intensity_areas(img1_masked)\n",
    "new_contours2, _ = detect_low_intensity_areas(img2_masked)\n",
    "\n",
    "# Draw contours on the original images\n",
    "img1_with_contours = draw_contours(cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR), contours1)\n",
    "img1_with_new_contours = draw_contours(img1_with_contours, new_contours1)\n",
    "\n",
    "img2_with_contours = draw_contours(cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR), contours2)\n",
    "img2_with_new_contours = draw_contours(img2_with_contours, new_contours2)\n",
    "\n",
    "# Resize images for display\n",
    "display_img1 = cv2.resize(img1_with_new_contours, (1000, 1000))\n",
    "display_img2 = cv2.resize(img2_with_new_contours, (1000, 1000))\n",
    "\n",
    "# display_cont = cv2.resize(img1_with_contours, (1000, 1000))\n",
    "\n",
    "# Show images\n",
    "cv2.imshow('Image 1 - Low Intensity Areas', display_img1)\n",
    "cv2.imshow('Image 2 - Low Intensity Areas', display_img2)\n",
    "\n",
    "# cv2.imshow('display_cont 1 - Low Intensity Areas', img1_with_new_contours)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image in grayscale\n",
    "img_path = \"C:/Users/thiwa/vision/Grout/t5.jpg\"\n",
    "img = cv2.imread(img_path, 0)\n",
    "\n",
    "# Resize the image for display\n",
    "display_img = cv2.resize(img, (1000, 1000))\n",
    "\n",
    "# Apply Gaussian blur to the image to reduce noise and improve circle detection\n",
    "blurred_img = cv2.GaussianBlur(display_img, (9, 9), 2)\n",
    "\n",
    "# Detect circles using HoughCircles\n",
    "circles = cv2.HoughCircles(blurred_img, cv2.HOUGH_GRADIENT, dp=0.1, minDist=50, param1=60, param2=35, minRadius=250, maxRadius=550)\n",
    "\n",
    "# circles = cv2.HoughCircles(blurred_img, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=10, param2=49, minRadius=70, maxRadius=300)\n",
    "\n",
    "# circles = cv2.HoughCircles(blurred_img, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=10, param2=49, minRadius=70, maxRadius=300)\n",
    "\n",
    "# If some circles are detected, convert the circle parameterqs (x, y, radius) to integers\n",
    "if circles is not None:\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "\n",
    "    # Draw the circles on the image\n",
    "    for (x, y, r) in circles:\n",
    "        cv2.circle(display_img, (x, y), r, (0, 255, 0), 1)\n",
    "        cv2.rectangle(display_img, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
    "\n",
    "# Create a window and set the mouse callback function to print intensity values on click\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Print the intensity value at the clicked point\n",
    "        intensity = param[y, x]\n",
    "        print(f\"Intensity at ({x}, {y}): {intensity}\")\n",
    "\n",
    "        # Display the intensity value on the image\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(display_img, str(intensity), (x, y), font, 0.5, (255, 255, 255), 2)\n",
    "        cv2.imshow(window_name, display_img)\n",
    "\n",
    "window_name = 'Detected Circles'\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.setMouseCallback(window_name, click_event, display_img)\n",
    "\n",
    "# Display the image with detected circles\n",
    "cv2.imshow(window_name, display_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity at (781, 300): [141 151 153]\n",
      "Intensity at (833, 352): [150 158 159]\n",
      "Intensity at (816, 369): [150 158 159]\n",
      "Intensity at (745, 298): [164 174 175]\n",
      "Intensity at (769, 254): [164 174 175]\n",
      "Intensity at (770, 231): [164 174 175]\n",
      "Intensity at (677, 320): [164 174 175]\n",
      "Intensity at (699, 259): [164 174 175]\n",
      "Intensity at (653, 290): [164 174 175]\n",
      "Intensity at (748, 421): [161 168 169]\n",
      "Intensity at (641, 437): [156 164 165]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def reduce_colors(image, k=5):\n",
    "    # Convert the image to float32 and reshape it to a 2D array of pixels\n",
    "    data = image.reshape((-1, 3)).astype(np.float32)\n",
    "    \n",
    "    # Define criteria for k-means (type, max_iter, epsilon)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    _, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert the centers to uint8 (since they are now the dominant colors)\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Map the labels back to the corresponding center (dominant color)\n",
    "    quantized_image = centers[labels.flatten()]\n",
    "    \n",
    "    # Reshape the quantized image back to the original image shape\n",
    "    quantized_image = quantized_image.reshape(image.shape)\n",
    "    \n",
    "    return quantized_image\n",
    "\n",
    "# Load the image in color\n",
    "img_path = \"C:/Users/thiwa/vision/Grout/t5.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Reduce the color resolution of the image\n",
    "k = 10  # Number of colors\n",
    "quantized_img = reduce_colors(img, k)\n",
    "\n",
    "# Resize the image for display\n",
    "display_img = cv2.resize(quantized_img, (1000, 1000))\n",
    "\n",
    "# Create a window and set the mouse callback function to print intensity values on click\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Print the intensity value at the clicked point\n",
    "        intensity = param[y, x]\n",
    "        print(f\"Intensity at ({x}, {y}): {intensity}\")\n",
    "\n",
    "        # Display the intensity value on the image\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(display_img, str(intensity), (x, y), font, 0.5, (255, 255, 255), 2)\n",
    "        cv2.imshow(window_name, display_img)\n",
    "\n",
    "window_name = 'Reduced Color Image'\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.setMouseCallback(window_name, click_event, quantized_img)\n",
    "\n",
    "# Display the quantized image\n",
    "cv2.imshow(window_name, display_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m center5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(centry)\n\u001b[0;32m     28\u001b[0m res5 \u001b[38;5;241m=\u001b[39m centry[lala\u001b[38;5;241m.\u001b[39mflatten()]\n\u001b[1;32m---> 29\u001b[0m res5 \u001b[38;5;241m=\u001b[39m \u001b[43mrep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m((img2\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m     31\u001b[0m display_img1 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(res2, (\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     32\u001b[0m display_img2 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(res5, (\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1000\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "#K mean\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img1 = cv.imread('C:/Users/thiwa/vision/Grout/t5.jpg')\n",
    "img2 = cv.imread('C:/Users/thiwa/vision/Grout/t5.jpg')\n",
    "K = 5\n",
    "\n",
    "Z = img1.reshape((-1,3))\n",
    "y = img2.reshape((-1,3))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "y = np.float32(y)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "ret,label,center=cv.kmeans(Z,K,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)\n",
    "rep,lala,centry=cv.kmeans(y,K,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "res2 = res.reshape((img1.shape))\n",
    "\n",
    "center5 = np.uint8(centry)\n",
    "res5 = centry[lala.flatten()]\n",
    "res5 = rep.reshape((img2.shape))\n",
    "\n",
    "display_img1 = cv.resize(res2, (1000, 1000))\n",
    "display_img2 = cv.resize(res5, (1000, 1000))\n",
    "\n",
    "cv.imshow('display_img1',display_img1)\n",
    "cv.imshow('display_img2',display_img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K mean and treshold\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def reduce_colors(image, k=10):\n",
    "    # Convert the image to float32 and reshape it to a 2D array of pixels\n",
    "    data = image.reshape((-1, 3)).astype(np.float32)\n",
    "    \n",
    "    # Define criteria for k-means (type, max_iter, epsilon)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    _, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert the centers to uint8 (since they are now the dominant colors)\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Map the labels back to the corresponding center (dominant color)\n",
    "    quantized_image = centers[labels.flatten()]\n",
    "    \n",
    "    # Reshape the quantized image back to the original image shape\n",
    "    quantized_image = quantized_image.reshape(image.shape)\n",
    "    \n",
    "    return quantized_image\n",
    "\n",
    "def detect_low_intensity_areas(image, threshold=20):\n",
    "    # Calculate the mean intensity of the image\n",
    "    mean_intensity = np.mean(image)\n",
    "    \n",
    "    # Thresholding to detect low intensity areas\n",
    "    _, mask = cv2.threshold(image, mean_intensity - threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours, mask\n",
    "\n",
    "def draw_contours(image, contours):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "def mask_detected_areas(image, mask):\n",
    "    # Apply the mask to the image to ignore detected areas\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))\n",
    "    return masked_image\n",
    "\n",
    "# Load images in color\n",
    "img1 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t12.jpg\")\n",
    "img2 = cv2.imread(\"C:/Users/thiwa/vision/Grout/t13.jpg\")\n",
    "\n",
    "# Reduce the color resolution of the images\n",
    "k = 8  # Number of colors\n",
    "quantized_img1 = reduce_colors(img1, k)\n",
    "quantized_img2 = reduce_colors(img2, k)\n",
    "\n",
    "# Convert the quantized images to grayscale\n",
    "gray_img1 = cv2.cvtColor(quantized_img1, cv2.COLOR_BGR2GRAY)\n",
    "gray_img2 = cv2.cvtColor(quantized_img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect low intensity areas and mask them\n",
    "contours1, mask1 = detect_low_intensity_areas(gray_img1)\n",
    "img1_masked = mask_detected_areas(gray_img1, mask1)\n",
    "\n",
    "contours2, mask2 = detect_low_intensity_areas(gray_img2)\n",
    "img2_masked = mask_detected_areas(gray_img2, mask2)\n",
    "\n",
    "# Detect new low intensity areas in the masked images\n",
    "new_contours1, _ = detect_low_intensity_areas(img1_masked)\n",
    "new_contours2, _ = detect_low_intensity_areas(img2_masked)\n",
    "\n",
    "# Draw contours on the original images\n",
    "img1_with_contours = draw_contours(cv2.cvtColor(gray_img1, cv2.COLOR_GRAY2BGR), contours1)\n",
    "img1_with_new_contours = draw_contours(img1_with_contours, new_contours1)\n",
    "\n",
    "img2_with_contours = draw_contours(cv2.cvtColor(gray_img2, cv2.COLOR_GRAY2BGR), contours2)\n",
    "img2_with_new_contours = draw_contours(img2_with_contours, new_contours2)\n",
    "\n",
    "# Resize images for display\n",
    "display_img1 = cv2.resize(img1_with_new_contours, (1000, 1000))\n",
    "display_img2 = cv2.resize(img2_with_new_contours, (1000, 1000))\n",
    "\n",
    "\n",
    "ori1 = cv2.resize(img1, (1000, 1000))\n",
    "ori2 = cv2.resize(img2, (1000, 1000))\n",
    "\n",
    "# Show images\n",
    "cv2.imshow('Image 1 - Low Intensity Areas', display_img1)\n",
    "cv2.imshow('Image 2 - Low Intensity Areas', display_img2)\n",
    "cv2.imshow('original img1', ori1)\n",
    "cv2.imshow('original img2', ori2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
